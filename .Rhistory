install.packages("survival")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages(c("dplyr", "stringr", "caret"))
install.packages(c("tseries", "forecast", "fGarch", "vars", "evir", "copula"))
install.packages(c("rugarch", "quantmod", "nnet", "PerformanceAnalytics"))
install.packages(c("expm", "httr", "pkgbuild", "RcppArmadillo", "rugarch", "sys", "vctrs"))
install.packages("expm")
yesa
yes
install.packages("expm")
install.packages(c("data.table", "expm", "rvest", "tinytex", "xfun"))
install.packages(c("dplyr", "fs", "tidyr"))
R.version.string
install.packages("pacman")
install.packages("corrplot")
install.packages("plotly")
install.packages(c("reshape2", "SentimentAnalysis", "stringr"))
install.packages(c("xtable", "xgboost", "tseries", "lubridate", "rvest", "Rcrawler", "purrr"))
install.packages(c("jsonlite", "geofacet", "foreign", "e1071", "tidyverse"))
install.packages(c("cowplot", "Boruta"))
install.packages(c("data.table", "skimr", "gmodels", "Hmisc"))
install.packages(c("cpp11", "Hmisc", "ps", "TTR"))
install.packages("ps")
install.packages("ps")
install.packages("ps")
install.packages(c("backports", "chron", "dplyr", "glue", "jsonlite", "MASS", "mgcv", "nlme", "processx", "ps", "RcppArmadillo", "rgeos", "SQUAREM", "tidyr", "TTR", "vctrs", "xgboost"))
install.packages("rgeos")
load("~/Desktop/NGA_2018_GHSP-W4_v01_M.xml")
install.packages(c("backports", "broom", "callr", "cli", "clipr", "codetools", "colorspace", "cowplot", "cpp11", "data.table", "dbplyr", "digest", "doParallel", "e1071", "foreach", "forecast", "Formula", "generics", "htmlTable", "htmlwidgets", "iterators", "KernSmooth", "knitr", "labeling", "lava", "lmtest", "lubridate", "magrittr", "MASS", "mclust", "nlme", "NLP", "openssl", "pillar", "ps", "R6", "RcppArmadillo", "readr", "recipes", "rgeos", "rlang", "rmarkdown", "rprojroot", "rstudioapi", "sandwich", "sf", "shape", "sp", "SQUAREM", "stringdist", "stringi", "survival", "testthat", "tibble", "tinytex", "tm", "vctrs", "withr", "xfun", "xts"))
library(readr)
NGA_2018_GHSP_W4_v01_M <- read_csv("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
NGA_2018_GHSP.W4_v01_M <- read.table("~/Desktop/NGA_2018_GHSP-W4_v01_M.xml", quote="\"", comment.char="")
View(NGA_2018_GHSP.W4_v01_M)
library(readr)
NGA_2018_GHSP_W4_v01_M <- read_csv("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
View(NGA_2018_GHSP_W4_v01_M)
View(NGA_2018_GHSP_W4_v01_M)
View(NGA_2018_GHSP_W4_v01_M)
read_xml(x, encoding = "", ..., as_html = FALSE, options = "NOBLANKS")
library(xml2)
read_xml(x, encoding = "", ..., as_html = FALSE, options = "NOBLANKS")
library(xml2)
NGA_2018_GHSP_W4_v01_M <- read_xml("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
library(xml2)
library(methods)
NGA_2018_GHSP_W4_v01_M <- xmlToDataFrame("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
NGA_2018_GHSP_W4_v01_M <- xmlParse("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
library(xml2)
library(methods)
NGA_2018_GHSP_W4_v01_M <- read.csv("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
NGA_2018_GHSP_W4_v01_M <- read_xml("Desktop/NGA_2018_GHSP-W4_v01_M.xml")
View(NGA_2018_GHSP_W4_v01_M)
install.packages(c("Hmisc", "processx"))
install.packages("Hmisc")
setwd("~/Documents/North Central/Post Planting")
setwd("~/Documents/North Central/Post Planting")
library('data.table')
setwd("~/Documents/North Central/Post Planting")
dfm<-fread("sect11c1a_plantingw4_NC.csv")
dfm1<-fread("sect11c1b_plantingw4_NC.csv")
dfm2<-fread("sect11e1_plantingw4_NC.csv")
dfm3<-fread("sect11e2_plantingw4_NC.csv")
dfm4<-fread("sect11f_plantingw4_NC.csv")
dfm5<-fread("sect11i_plantingw4_NC.csv")
dfm6<-fread("sect11j_plantingw4_NC.csv")
dfm7<-fread("sect11k1_plantingw4_NC.csv")
dfm8<-fread("sect11k2_plantingw4_NC.csv")
dfm9<-fread("sect11k3_plantingw4_NC.csv")
dfm10<-fread("sect1_plantingw4_NC.csv")
dfm11<-fread("sect3_plantingw4_NC.csv")
dfm12<-fread("sect3q38_plantingw4_NC.csv")
dfm13<-fread("sect5_plantingw4_NC.csv")
dfm14<-fread("sect7a_plantingw4_NC.csv")
dfm15<-fread("sect7b_plantingw4_NC.csv")
dfm16<-fread("sect9_plantingw4_NC.csv")
dfm17<-fread("secta_plantingw4_NC.csv")
dfm18<-fread("sect11a1_plantingw4_NC.csv")
dfm19<-fread("sect11b1_plantingw4_NC.csv")
dfm20<-fread("sect11l2_plantingw4_NC.csv")
dfmjoin<-rbind(dfm,dfm1,dfm2,dfm3,dfm4,dfm5,dfm6,dfm7,dfm8,dfm9,dfm10,dfm11,dfm12,dfm13,dfm14,dfm15,dfm16,dfm17,dfm18,dfm19,dfm20,fill=TRUE)
write.csv(dfmjoin,"NC_PP.csv")
dfmjoin<-rbind(dfm,dfm1,dfm2,dfm3,dfm4,dfm5,dfm6,dfm7,dfm8,dfm9,dfm10,dfm11,dfm12,dfm13,dfm14,dfm15,dfm16,dfm17,dfm18,dfm19,dfm20,fill=TRUE)
View(dfmjoin)
setwd("~/Documents/North Central/Post Harvest Agriculture")
setwd("~/Documents/North Central/Post Harvest Agriculture")
setwd("~/Documents/North Central/Post Harvest Agriculture")
dfr<-fread("secta11c2_harvestw4_NC.csv")
dfr1<-fread("secta11c3_harvestw4_NC.csv")
dfr2<-fread("secta11c3q12_harvestw4_NC.csv")
dfr3<-fread("secta2a_harvestw4_NC.csv")
dfr4<-fread("secta2b_harvestw4_NC.csv")
dfr5<-fread("secta3i_harvestw4_NC.csv")
dfr6<-fread("secta3ii_harvestw4_NC.csv")
dfr7<-fread("secta3iii_harvestw4_NC.csv")
dfr8<-fread("secta4_harvestw4_NC.csv")
dfr9<-fread("secta9a_harvestw4_NC.csv")
dfr10<-fread("sectaa_harvestw4_NC.csv")
dfr11<-fread("sectaphl1_harvestw4_NC.csv")
dfr12<-fread("sectaphl2_harvestw4_NC.csv")
dfr13<-fread("secta1_harvestw4_NC.csv")
dfrjoin<-rbind(dfr,dfr1,dfr2,dfr3,dfr4,dfr5,dfr6,dfr7,dfr8,dfr9,dfr10,dfr11,dfr12,dfr13,fill=TRUE)
View(dfrjoin)
write.csv(dfrjoin,"NC_PHA.csv")
setwd("~/Documents/North Central/NC Merged")
setwd("~/Documents/North Central/NC Merged")
dfre<-fread("NC_PP.csv")
dfre1<-fread("NC_PH.csv")
dfrejoin<-rbind(dfre,dfre1,fill=TRUE)
View(dfrjoin)
write.csv(dfrejoin,"NC_PP&PH.csv")
View(dfrejoin)
install.packages(c("Hmisc", "isoband", "slam", "tau"))
install.packages("slam")
install.packages("slam")
install.packages(c("backports", "data.table", "jsonlite", "nlme", "ps", "quantmod", "slam", "tseries"))
install.packages("nlme")
install.packages(c("htmlwidgets", "nlme"))
install.packages(c("devtools", "sos"))
install.packages(c("RODBC", "RMySQL", "ROracle", "RPostgreSQL", "RSQLite", "R4CouchDB", "RCassandra"))
install.packages(c("XML", "XLConnect"))
install.packages(c("broom", "copula", "foreign", "ggrepel", "Matrix", "nlme", "pkgbuild", "plotly", "RcppEigen", "rmarkdown", "RMySQL", "tau", "testthat", "tinytex", "vctrs"))
install.packages("Matrix")
install.packages(c("cowplot", "data.table", "ggplot2", "Matrix", "rlang", "xgboost"))
install.packages(c("BH", "boot", "brio", "broom", "class", "cli", "cpp11", "crayon", "crosstalk", "DBI", "dbplyr", "diffobj", "dplyr", "DT", "expm", "fansi", "forcats", "gert", "ggrepel", "glmnet", "hexbin", "hms", "htmltools", "knitr", "ks", "Matrix", "memoise", "nlme", "nnet", "plotly", "pROC", "rappdirs", "Rcpp", "RcppArmadillo", "repr", "reprex", "RSQLite", "sf", "sp", "spatial", "SQUAREM", "tibble", "tinytex", "usethis", "waldo", "webdriver", "withr", "xfun", "xgboost"))
install.packages("RcppArmadillo")
install.packages(c("boot", "cachem", "cluster", "gert", "lifecycle", "MASS", "mgcv", "mime", "promises", "RcppArmadillo", "SentimentAnalysis", "testthat", "XLConnect"))
install.packages(c("broom", "cli", "data.table", "glmnet", "pillar", "pkgload", "rmarkdown"))
install.packages("glmnet")
install.packages(c("farver", "glmnet", "Hmisc", "lubridate", "ps", "tibble", "units"))
install.packages(c("abind", "anytime", "BH"))
install.packages("corrr")
install.packages(c("dummies", "dygraphs"))
install.packages(c("echarts4r", "esquisse", "extraDistr"))
install.packages(c("feather", "flexdashboard"))
install.packages("furrr")
install.packages(c("gbm", "gargle"))
install.packages("githubinstall")
install.packages(c("googleAnalyticsR", "googleAuthR", "googleVis", "googlenlp"))
install.packages(c("inline", "instaR"))
install.packages("janitor")
install.packages(c("lambda.r", "latexpdf"))
install.packages("leaflet")
install.packages(c("loo", "maps"))
install.packages("mlr")
install.packages(c("officer", "network"))
install.packages("plumber")
install.packages("pryr")
install.packages(c("rjson", "rio"))
install.packages("rlist")
install.packages("rtweet")
install.packages("sna")
install.packages(c("urltools", "validate"))
install.packages(c("gargle", "Hmisc", "ipred", "isoband", "officer", "rio", "tidyr", "tinytex"))
library(readxl)
KPMG_VI_New_raw_data_update_final <- read_excel("Downloads/Forage/KPMG/KPMG_VI_New_raw_data_update_final.xlsx")
View(KPMG_VI_New_raw_data_update_final)
runExample("01_hello")
library(shiny)
runExample("01_hello")
install.packages(c("bitops", "boot", "brio", "broom", "bslib", "cachem", "callr", "car", "caret", "caTools", "class", "cli", "cluster", "colorspace", "corrplot", "cpp11", "curl", "dbplyr", "dendextend", "desc", "devtools", "diffobj", "dplyr", "DT", "e1071", "echarts4r", "ellipsis", "esquisse", "fansi", "fields", "forecast", "formatR", "furrr", "gargle", "gert", "ggplot2", "gh", "glmnet", "googleAnalyticsR", "googleAuthR", "gtools", "haven", "highr", "hms", "htmlTable", "httpuv", "inline", "ipred", "jquerylib", "KernSmooth", "knitr", "ks", "later", "lattice", "lava", "lme4", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "mvtnorm", "network", "nnet", "officer", "openssl", "openxlsx", "parallelly", "parallelMap", "pcaPP", "pillar", "pkgload", "plot3D", "plotly", "plumber", "processx", "raster", "RcppArmadillo", "RCurl", "recipes", "remotes", "reprex", "rio", "rJava", "rlang", "rmarkdown", "RMySQL", "RSQLite", "rversions", "rvest", "sandwich", "sass", "settings", "sf", "shape", "shinyWidgets", "skimr", "sos", "spam", "spatial", "statnet.common", "stringi", "survival", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "units", "utf8", "validate", "vctrs", "viridis", "viridisLite", "waldo", "withr", "xfun", "xgboost", "XLConnect", "XML", "zip", "zoo"))
install.packages(c("blob", "cli", "corrplot", "countrycode", "datamods", "esquisse", "fastmatch", "gargle", "googledrive", "googlesheets4", "isoband", "ks", "multicool", "officer", "parallelly", "ranger", "Rcpp", "RcppArmadillo", "readr", "seriation", "sf", "stringi", "styler", "tau", "testthat", "tibble", "wk"))
install.packages("sf")
install.packages(c("broom", "credentials", "e1071", "gss", "haven", "jpeg", "matrixStats", "pillar", "pryr", "readr", "reprex", "rmarkdown", "RPostgreSQL", "rsconnect", "rvest", "sf", "stringdist", "tinytex", "utf8", "vroom", "xfun", "XLConnect"))
install.packages("sf")
setwd("~/Downloads/Forage/ANZ")
setwd("~/Downloads/Forage/ANZ")
library(stringr)
library(lubridate)
library(tidyverse)
library(modelr)
library(sp)
library(leaflet)
library(geosphere)
library(knitr)
library(rpart)
install.packages("geosphere")
install.packages(c("cachem", "gert", "httpuv", "later", "latexpdf", "matrixStats", "packrat", "R6", "RCurl", "RJSONIO", "RSQLite", "survival", "waldo", "XML"))
library(stringr)
library(lubridate)
library(tidyverse)
library(modelr)
library(sp)
library(leaflet)
library(geosphere)
library(knitr)
library(rpart)
library(readxl)
# Task 1 Exploratory data analysis
# 1.1 Load the transaction dataset
df <- read_excel("ANZ synthesised transaction dataset.xlsx")
# View the summary of the dataset
summary(df)
str(df)
# Edit the format of date column
df$date<- as.Date(df$date,format = "%d/%m/%Y")
# The dateset only contain records for 91 days, one day is missing
DateRange <- seq(min(df$date), max(df$date), by = 1)
DateRange[!DateRange %in% df$date] # 2018-08-16 transactions are missing
# Derive weekday and hour data of each transaction
df$extraction = as.character(df$extraction)
df$hour = hour(as.POSIXct(substr(df$extraction,12,19),format="%H:%M:%S"))
df$weekday = weekdays(df$date)
# Verify the one -to -one link of account_id and customer_id
df %>% select(account,customer_id) %>%
unique() %>%
nrow()
# Split customer & merchant lat_long into individual columns for analysis
dfloc = df[,c("long_lat","merchant_long_lat")]
dfloc<- dfloc %>% separate("long_lat", c("c_long", "c_lat"),sep=' ')
dfloc<- dfloc %>% separate("merchant_long_lat", c("m_long", "m_lat"),sep=' ')
dfloc<- data.frame(sapply(dfloc, as.numeric))
df <- cbind(df,dfloc)
# Check the range of customer location
# Filtering out transactions for those who don't reside in Australia
# Reference: http://www.ga.gov.au/scientific-topics/national-location-information/dimensions/continental-extremities
df_temp <- df %>%
filter (!(c_long >113 & c_long <154 & c_lat > (-44) & c_lat < (-10)))
length(unique(df_temp$customer_id))
# Check the distribution of missing values
apply(df, 2, function(x) sum(is.na(x)| x == ''))
# check the number of unique values for each column
apply(df, 2, function(x) length(unique(x)))
# 1.3 Gather some interesting overall insights about the data
# Filtering out purchase transactions only
# Assuming purchase transactions must be associated with a merchant (have a merchant Id)
df_temp <- df %>% filter(merchant_id != '' )
# It turned out that is equivilent to excluding following categories of transactions
df_csmp <- df %>%filter(!(txn_description %in% c('PAY/SALARY',"INTER BANK", "PHONE BANK","PAYMEN T")))
summary(df_csmp)
# Visualise the distribution of transaction amount
hist(df_csmp$amount[!df_csmp$amount %in% boxplot.stats(df_csmp$amount)$out], #exclude outliers
xlab= 'Transaction Amount', main = 'Histogram of purchase transaction amount')
hist(df$amount[!df$amount %in% boxplot.stats(df$amount)$out], #exclude outliers
xlab= 'Transaction Amount',main = 'Histogram of overall transaction amount')
# Visualise customers’average monthly transaction volume.
df2 <- df %>%
group_by(customer_id) %>%
summarise(mon_avg_vol = round(n()/3,0))
hist(df2$mon_avg_vol,
xlab= 'Monthly transaction volume', ylab='No. of customers', main = "Histogram of customers' monthly transaction volume")
# 1.4 Segment the dataset by transaction date and time.
# Visualise transaction volume over an average week.
df3 <- df %>%
select(date,weekday) %>%
group_by(date,weekday) %>%
summarise(daily_avg_vol = n()) %>%
group_by(weekday) %>%
summarise(avg_vol=mean(daily_avg_vol,na.rm=TRUE ))
df3$weekday <- factor(df3$weekday, levels=c( "Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
ggplot(df3,aes(x=weekday, y=avg_vol)) +geom_point()+geom_line(aes(group = 1))+
ggtitle('Average transaction volume by weekday') +
labs(x='Weekday',y='Transaction volume')
# visualize transaction volume over an average week.
df4 <- df %>%
select(date,hour) %>%
group_by(date,hour) %>%
summarize(trans_vol=n()) %>%
group_by(hour) %>%
summarize(trans_vol_per_hr = mean(trans_vol,na.rm=TRUE))
ggplot(df4,aes(x=hour,y=trans_vol_per_hr))+geom_point()+geom_line(aes(group = 1))+
ggtitle('Average transaction volume by hour') +
labs(x='Hour',y='Transaction volume') + expand_limits( y = 0)
# 1.5 Challenge: Exploring location information
# Exclude the single foreign customer whose location information was incorrectly stored (i.e latitude 573)
df_temp <- df_csmp %>%
filter (c_long >113 & c_long <154 & c_lat > (-44) & c_lat < (-10))
dfloc = df_temp [,c("c_long", "c_lat","m_long", "m_lat")]
dfloc<- data.frame(sapply(dfloc, as.numeric))
dfloc$dst <- distHaversine(dfloc[, 1:2], dfloc[, 3:4]) / 1000
hist(dfloc$dst[dfloc$dst<100], main = "Distance between customer and merchants",xlab= 'Distance(km)' )
# To validate, we could further plot the location of the customer and the merchants he/she trades with on a map.
merch_dist <- function (id ){
### This function takes in a customer Id and plot the location of the customer and all merchants he/she have traded with.
cus_icon<- makeAwesomeIcon(icon = 'home', markerColor = 'green')
l = subset (df_csmp[,c("customer_id","m_long","m_lat")], customer_id == id)
l <- l[c("m_long","m_lat")]
cus_loc <- unique(subset (df_csmp[,c("customer_id","long_lat")], customer_id == id))
cus_loc <- cus_loc %>% separate("long_lat", c("long", "lat"),sep=' ')
df_t = data.frame(longtitude = as.numeric(l$m_long), latitude = as.numeric(l$m_lat))
coordinates(df_t) <- ~longtitude+latitude
leaflet(df_t) %>% addMarkers() %>% addTiles() %>%
addAwesomeMarkers(
lng=as.numeric(cus_loc$long), lat=as.numeric(cus_loc$lat),
icon = cus_icon)
}
merch_dist(id ='CUS-51506836' )
# To validate, we could further plot the location of the customer and the merchants he/she trades with on a map.
merch_dist <- function (id ){
### This function takes in a customer Id and plot the location of the customer and all merchants he/she have traded with.
cus_icon<- makeAwesomeIcon(icon = 'home', markerColor = 'green')
l = subset (df_csmp[,c("customer_id","m_long","m_lat")], customer_id == id)
l <- l[c("m_long","m_lat")]
cus_loc <- unique(subset (df_csmp[,c("customer_id","long_lat")], customer_id == id))
cus_loc <- cus_loc %>% separate("long_lat", c("long", "lat"),sep=' ')
df_t = data.frame(longtitude = as.numeric(l$m_long), latitude = as.numeric(l$m_lat))
coordinates(df_t) <- ~longtitude+latitude
leaflet(df_t) %>% addMarkers() %>% addTiles() %>%
addAwesomeMarkers(
lng=as.numeric(cus_loc$long), lat=as.numeric(cus_loc$lat),
icon = cus_icon)
}
merch_dist(id ='CUS-51506836' )
merch_dist(id ='CUS-51506836' )
merch_dist(id ='CUS-51506836' )
else stop("missing values in object")
else stop('CUS-51506836')
merch_dist(id ='CUS-51506836' )
stop("missing values in object")
na.fail.default(structure(list(longtitude = c(153.08, 153.05,153.01, 151.21, NA, 153.06, 153.06, NA, 152.89, 151.21, 153.04,152.28, 152.98, 152.95, 153.17, 151.93, NA, 151.72, 152.96, 153.1,152.91, 152.98, 153.01, 145.03, NA, 153.12, 153.1, 151.93, 152.91,  ...
UseMethod("na.fail"))(structure(list(longtitude = c(153.08, 153.05,153.01, 151.21, NA, 153.06, 153.06, NA, 152.89, 151.21, 153.04, 152.28, 152.98, 152.95, 153.17, 151.93, NA, 151.72, 152.96, 153.1,  ...
model.frame(value, object, na.action = na.fail)
`coordinates<-`(`*tmp*`, value = ~longtitude + latitude)
`coordinates<-`(`*tmp*`, value = ~longtitude + latitude)
merch_dist(id = "CUS-51506836")
merch_dist(id = "CUS-51506836")
# Task 2 Basic predictive modelling
# 2.1 Identify the annual salary for each customer
# Firstly check the salary payment frequency of each customer
df_inc = data.frame(customer_id= unique(df_csmp$customer_id)) # Create a data frame to store result
# create a mode function that will be used to find out what is the salary payment frequency
Mode <- function(x) {
ux <- unique(x) ux[which.max(tabulate(match(x, ux)))]
}
# create a mode function that will be used to find out what is the salary payment frequency
Mode <- function(x) {ux <- unique(x) ux[which.max(tabulate(match(x, ux)))]}
# create a mode function that will be used to find out what is the salary payment frequency
Mode <- function(x) {
ux <- unique(x) ux[which.max(tabulate(match(x, ux)))]
}
# create a mode function that will be used to find out what is the salary payment frequency
Mode <- function(x) {
ux <- unique(x) ux[which.max(tabulate(match(x, ux)))]}
# create a mode function that will be used to find out what is the salary payment frequency
Mode <- function(x) {ux <- unique(x) ux[which.max(tabulate(match(x, ux)))]}
setwd("~/Downloads/Forage/Quantium")
# Load required libraries and datasets
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
# Load required datasets
transactionData <‐ fread("QVI_transaction_data.xlsx")
customerData <‐ fread("QVI_purchase_behaviour.csv")
# Load required datasets
transactionData <‐ read_excel("QVI_transaction_data.xlsx")
customerData <‐ read_csv("QVI_purchase_behaviour.csv")
# Load required libraries and datasets
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
library(readxl)
# Load required datasets
transactionData <‐ read_excel("QVI_transaction_data.xlsx")
customerData <‐ read_csv("QVI_purchase_behaviour.csv")
# Load required datasets
transactionData <- read_excel("QVI_transaction_data.xlsx")
customerData <- read_csv("QVI_purchase_behaviour.csv")
# Exploratory data analysis
#### Examine transaction data
str(transactionData)
#### Convert DATE column to a date format
#### A quick Google search tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <‐ as.Date(transactionData$DATE, origin = "1899‐12‐30")
#### Convert DATE column to a date format
#### A quick Google search tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899‐12‐30")
#### Convert DATE column to a date format
#### A quick Google search tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899‐12‐30")
#### Convert DATE column to a date format
#### A quick Google search tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = 1899‐12‐30)
#### Convert DATE column to a date format
#### A quick Google search tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899‐12‐30")
